{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "from textstat import flesch_kincaid_grade\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "7A8y37niArdG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data Cleaning\n",
        "First, load and clean your dataset:"
      ],
      "metadata": {
        "id": "5YZ9-P55Fp7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Display initial data\n",
        "print(df.head())\n",
        "\n",
        "# Basic cleaning\n",
        "df.dropna(subset=['title', 'selftext'], inplace=True)  # Remove rows with missing 'title' or 'selftext'\n",
        "df.drop_duplicates(inplace=True)  # Remove duplicate rows\n",
        "\n",
        "# Remove irrelevant characters (optional)\n",
        "df['title'] = df['title'].str.replace(r'\\W', ' ', regex=True)  # Remove non-word characters\n",
        "df['selftext'] = df['selftext'].str.replace(r'\\W', ' ', regex=True)  # Remove non-word characters\n",
        "\n",
        "# Reset index after dropping rows\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "8CFoWvqkI7Zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Data Cleaning\n",
        "df.dropna(subset=['title', 'selftext'], inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df['title'] = df['title'].str.replace(r'\\W', ' ', regex=True)\n",
        "df['selftext'] = df['selftext'].str.replace(r'\\W', ' ', regex=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "Uc40TUi0KiHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A. ADHD-Related Keywords Frequency:"
      ],
      "metadata": {
        "id": "hl2hGYsKFEhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Example keywords related to ADHD\n",
        "keywords = ['attention', 'hyperactivity', 'impulsivity', 'distraction', 'forgetfulness', 'restlessness', 'talkativeness']\n",
        "\n",
        "# Function to count keyword occurrences\n",
        "def count_keywords(text, keywords):\n",
        "    return sum(text.lower().count(keyword) for keyword in keywords)\n",
        "\n",
        "# Apply the function to the dataset\n",
        "df['title_keywords_count'] = df['title'].apply(lambda x: count_keywords(x, keywords))\n",
        "df['selftext_keywords_count'] = df['selftext'].apply(lambda x: count_keywords(x, keywords))\n"
      ],
      "metadata": {
        "id": "zMJmxzC6FGi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "B. Sentiment Score:\n",
        "\n",
        "Analyze sentiment using libraries like VADER or TextBlob."
      ],
      "metadata": {
        "id": "NgW27L-uFKYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def get_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return analysis.sentiment.polarity  # Returns a value between -1 (negative) and 1 (positive)\n",
        "\n",
        "df['title_sentiment'] = df['title'].apply(get_sentiment)\n",
        "df['selftext_sentiment'] = df['selftext'].apply(get_sentiment)\n"
      ],
      "metadata": {
        "id": "RJUuuvnuFJkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C. Topic Modeling:\n",
        "\n",
        "Use Latent Dirichlet Allocation (LDA) for topic modeling."
      ],
      "metadata": {
        "id": "kO-hErWNFQCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_title = vectorizer.fit_transform(df['title'])\n",
        "X_selftext = vectorizer.fit_transform(df['selftext'])\n",
        "\n",
        "# Apply LDA\n",
        "lda_title = LatentDirichletAllocation(n_components=5, random_state=0)\n",
        "lda_selftext = LatentDirichletAllocation(n_components=5, random_state=0)\n",
        "\n",
        "lda_title.fit(X_title)\n",
        "lda_selftext.fit(X_selftext)\n",
        "\n",
        "# Get the topic distribution for each document\n",
        "df['title_topic_distribution'] = list(lda_title.transform(X_title))\n",
        "df['selftext_topic_distribution'] = list(lda_selftext.transform(X_selftext))\n"
      ],
      "metadata": {
        "id": "RVkoh4mhFQrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "D. Named Entity Recognition (NER):\n",
        "\n",
        "Use spaCy for NER"
      ],
      "metadata": {
        "id": "pAV1yhhXFUDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    return [ent.text for ent in doc.ents]\n",
        "\n",
        "df['title_entities'] = df['title'].apply(extract_entities)\n",
        "df['selftext_entities'] = df['selftext'].apply(extract_entities)\n"
      ],
      "metadata": {
        "id": "thZpUpSZFVyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "E. Text Complexity Score:\n",
        "\n",
        "Calculate readability scores like Flesch-Kincaid."
      ],
      "metadata": {
        "id": "yg_mof3oFZbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textstat import flesch_kincaid_grade\n",
        "\n",
        "df['title_complexity'] = df['title'].apply(flesch_kincaid_grade)\n",
        "df['selftext_complexity'] = df['selftext'].apply(flesch_kincaid_grade)\n"
      ],
      "metadata": {
        "id": "Ql3eii72FZ-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F. Contextual Relevance Score:\n",
        "\n",
        "Use keyword matching or similarity measures to evaluate relevance.\n",
        "python"
      ],
      "metadata": {
        "id": "xXfgMEH1FbGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_relevance_score(text, keyword_list):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform([text] + keyword_list)\n",
        "    similarity_matrix = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])\n",
        "    return similarity_matrix.mean()\n",
        "\n",
        "keywords_list = ['ADHD', 'attention deficit', 'hyperactivity', 'impulsivity']  # Example keywords\n",
        "df['title_relevance'] = df['title'].apply(lambda x: get_relevance_score(x, keywords_list))\n",
        "df['selftext_relevance'] = df['selftext'].apply(lambda x: get_relevance_score(x, keywords_list))\n"
      ],
      "metadata": {
        "id": "CQuiSIokFelo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "G. Emotional Tone:\n",
        "\n",
        "Use sentiment analysis or specialized libraries."
      ],
      "metadata": {
        "id": "59Ba5o_8Fgo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_emotional_tone(text):\n",
        "    sentiment = analyzer.polarity_scores(text)\n",
        "    return sentiment['compound']  # Returns a value between -1 (negative) and 1 (positive)\n",
        "\n",
        "df['title_emotional_tone'] = df['title'].apply(get_emotional_tone)\n",
        "df['selftext_emotional_tone'] = df['selftext'].apply(get_emotional_tone)\n"
      ],
      "metadata": {
        "id": "xF1J5lShFhUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "H. Question Type:\n",
        "\n",
        "Classify the type of text if applicable."
      ],
      "metadata": {
        "id": "8mefy_TZFing"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_question_type(text):\n",
        "    if '?' in text:\n",
        "        return 'Inquiry'\n",
        "    elif 'complain' in text.lower():\n",
        "        return 'Complaint'\n",
        "    else:\n",
        "        return 'Statement'\n",
        "\n",
        "df['question_type'] = df['title'].apply(classify_question_type)\n"
      ],
      "metadata": {
        "id": "ZOCoVKllFi49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 11: Transformer Model Embeddings"
      ],
      "metadata": {
        "id": "v-Tri_e_KxnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pre-trained Transformer Model\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import tensorflow as tf\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_bert_embeddings(texts, tokenizer, model, max_len=128):\n",
        "    encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=max_len, return_tensors='tf')\n",
        "    outputs = model(encodings['input_ids'], attention_mask=encodings['attention_mask'])\n",
        "    return outputs.last_hidden_state[:, 0, :]  # Use [CLS] token embeddings\n",
        "\n",
        "title_embeddings = get_bert_embeddings(df['title'], tokenizer, bert_model)\n",
        "selftext_embeddings = get_bert_embeddings(df['selftext'], tokenizer, bert_model)\n",
        "\n",
        "title_embeddings_np = title_embeddings.numpy()\n",
        "selftext_embeddings_np = selftext_embeddings.numpy()\n"
      ],
      "metadata": {
        "id": "hWNV7P-UKzrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 12: Combine Features"
      ],
      "metadata": {
        "id": "z3xqSeNWK0pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine Features\n",
        "title_embeddings_df = pd.DataFrame(title_embeddings_np, index=df.index)\n",
        "selftext_embeddings_df = pd.DataFrame(selftext_embeddings_np, index=df.index)\n",
        "\n",
        "feature_df = pd.concat([\n",
        "    df[['title_keywords_count', 'selftext_keywords_count', 'title_sentiment', 'selftext_sentiment',\n",
        "        'title_complexity', 'selftext_complexity', 'title_relevance', 'selftext_relevance',\n",
        "        'title_emotional_tone', 'selftext_emotional_tone']],\n",
        "    title_embeddings_df,\n",
        "    selftext_embeddings_df\n",
        "], axis=1)\n",
        "\n",
        "# Example Labels (Replace with actual labels)\n",
        "labels = pd.get_dummies(df['question_type'])\n"
      ],
      "metadata": {
        "id": "j-aWBQy_K24G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 13: Train-Test Split"
      ],
      "metadata": {
        "id": "WNVari-yK4jT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
      ],
      "metadata": {
        "id": "o82CQp5wK5a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 14: Define and Train Deep Learning Model"
      ],
      "metadata": {
        "id": "cCBVm6KZK7GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and Train Deep Learning Model\n",
        "model = Sequential([\n",
        "    Dense(256, activation='relu', input_dim=feature_df.shape[1]),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(labels.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Plot Training History\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KTc7pQa8K_Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "bZpT19L3LBTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "id": "df8YFVR7LBtW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}